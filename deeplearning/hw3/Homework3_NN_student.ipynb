{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3: Back-propagation Implementation\n",
    "## 2020 CS 474/574: Deep Learning\n",
    "## Due: 10/15/2020\n",
    "\n",
    "### Your name here: Graeme Holliday\n",
    "\n",
    "\n",
    "### Tasks:\n",
    "1. Implement the sofmax function. 5 points\n",
    "\n",
    "2. Implement the Layer class. 10 points.\n",
    "\n",
    "3. Complete the NN class. 70 points.\n",
    "\n",
    "    3.1: implement the 'add' function. 5 points\n",
    "    \n",
    "    3.2: implement the cross-entropy loss. 5 points \n",
    "    \n",
    "    3.3: implement the forward propagation process. 5 points.\n",
    "    \n",
    "    3.4: implement the prediction function. 5 points\n",
    "    \n",
    "    3.5: complete 'train' function. 10 points.\n",
    "    \n",
    "    3.6: implement the BP algorithm. 30 points\n",
    "    \n",
    "    3.7: update all weights and bias. 5 points\n",
    "    \n",
    "    3.8: calculate the accuracy. 5 points \n",
    "    \n",
    "4. Evaluation. 15 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVkAAAD7CAYAAADAUeeKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2deXgUVfa/38suoKyyRwUVAUFFEURQUUQyLoM4DqIiiszAKAiuPxHcQERUxHHlK4oCCm6DgKKIoo6AC4MoKJgHBFEEwxJZlC0xyf39UbnV3Ukn3enuW93VOe/z1NPpquqqw6cvt0+de+65SmuNIAiCYIdKyTZAEAQhnZFOVhAEwSLSyQqCIFhEOllBEASLSCcrCIJgEelkBUEQLBJXJ6uUylRKrVNKbVBKjUqUUYKD6GsP0dYeom0oKtY8WaVUZWA90AvYAqwArtRaf5848youoq89RFt7iLYlqRLHZzsDG7TWPwIopV4D+gCliqmU8vXMB6218vB25dJXtC0X0nbtIdoWI55wQXPgl6D3W4r2haCUGqKU+kop9VUc96qIRNRXtI0Zabv2EG2LEY8nG673LvGLpLWeCkwF//9ieUxEfUXbmJG2aw/RthjxeLJbgIyg9y2AX+MzRwhC9LWHaGsP0bYY8XSyK4DjlVItlVLVgP7A24kxS0D0tYloaw/Rthgxhwu01vlKqeHAIqAy8KLWem3CLKvgiL72EG3tIdqWJOYUrphu5vPYi8cj4OVCtLWL6GuPdNdWZnwJ5aJHjx4sXryYxYsXU1hYSGFhofv+7LPPTrZ5gpBySCcrCIJgEd+HCypXrky9evVK7L///vsBqF27NgDt2rUD4PLLL+eVV14B4KyzzgIgPz+fqVOnAjBs2LBS71WRH7m6desGwOLFi6lWrVrYc3Jzc6lZs2ZM109lbSF1Hmn//ve/A/DSSy8BzveyevXqiJ9LZX2Tqe2TTz4JwPDhw1HKkahv374AzJs3L6prRNI2njxZz2jVqhU1atQAoHfv3gD06tULgLp163LGGWdEvMbvv/8OwBtvvEHnzp0Bp1MA+OWXX/joo48Sbnc6cP755wMwZ84cAKpXr475Yc7LywOgoKAAgMMOO4zMzEwAPv7445Bz0pk+ffoA0LBhQ6ZNm2b1Xqat//DDD1bvk+7cdtttAAwdOhSAYGcz0Y6nhAsEQRAsktKerHmc/+CDD6hevXpM1zC/SiZ8sG/fPl544QXA8WABtm3bFtUjV0WhVq1aAJx77rluaMWEXYLZvn07ABMmTABgypQpvPfeewA88cQTANxyyy3W7U025qmqffv2Vj3ZSpUq0aZNGwAaN24M4D7iCuWjVatWAFSpYr8LFE9WEATBIintyWZlZQFw4MCBqDzZTZs2AfDHH39w4oknAoF44b///W9LVqYf7777LhB4kiiNjAxn9uThhx8OwPr16znhhBMA6NSpk0ULU4srr7wSgO+++87qfTIyMvjLX/4CwKeffgrAqlWrrN4z3ejXrx8AgwYNCtm/Y8cOunfvDsCvvyZ2FnBKd7I5OTkA3HHHHa44X3zxBQD33Xefe96WLVsAOPnkkwEnJGD+k48bN84ze/1Ojx49AOjSpQsQ+ii6bt06wBlxvfPOOwFHZwh8J7t27eLFF18s8dl0p1Ilbx4I3347MDt1zZo1ntwznbj44ovdUGFxp+2RRx5h48aNVu4r4QJBEASL+CZPtm7dugDs3bsXCDzSZmZmMnLkSACeeuqpeE0sk3TNNQzOgQVC8mDNgOA555wDwKWXXkrHjh0B59cfnIFDQ2FhIQB//vkn4AwKLVmyJKINqawthNfXpFOZf9/nn3/uPg3YYOPGjbRs2RLADRssWrQoqs+msr5e5ckuXLjQTQE1mCe0tm3bxnxdmVYrCIKQRFI6JhvMnj17Qt7v2rXL/fvGG28E4JlnngEC3pQQmQ4dOrgpWCZOdeDAAcB5avi///s/wBlMBHj55Zd5+eWXI17XpMY88MADrhecbpjZV7bTgJo1awZAo0aN3H3r16+3es90wqS79e7d203pPHToEAD33HOP9fuLJysIgmAR33iyxfnXv/4FwGmnneamDZkMhNdeey1pdvkFM015+vTpnHLKKUBgmvE///lPAD766KOYaxEYjBeWjphsFsPKlSut3Gf27NmAM0nEZNyYsQmhdI4//niAsFPmTe2H//znP9bt8G0na9KHLrvsMr755hsA99H2n//8J0uXLgVg7NixQOLnI/sdM0BjOlgI5HtGWxhDCOXLL7+M+xp169Z1v4d//OMfAJx00knu8fHjxwOh4TIhPFdccQUAzZsH1nFcu9apH+5FmMAg4QJBEASL+NaTNWRlZbnlCZ9++mnAmXN/7rnnAoE592YuvalXUNExg4RKqZCJBvFSfBJCRZqU0KBBg7D7zzzzTMApywlOUjxAy5Yt3cFGk1qklCI/Px8IpBeZWYuVKlWKKh1OgOuvv54xY8aE7NuwYYNbJW737t2e2SKerCAIgkV878kCbuUjM9Vw2rRpbpHuW2+9FQgEwUeMGMHPP/+cBCtTg4EDBwKBugNaa7dWbCIwsW/zans+fzLZv39/yPvJkydz9913lziv+OBf8IQNM0/ePEV8/vnn7vTZrVu3AgGvq0qVKlKrIALm/7mZPhvM5s2bE16XIBrSopM1LF++HICzzz7b7Uwee+wxAC655BIAjjvuOLd4TEXEZAuYR9cDBw7w3HPPxXVNk6kwZcoUd58p7mO+h3TEFOueNGkSQKmzvcyMuNdffx2Ab7/9Fog8W2v06NFA4Dvz8hHXr5j/7+EGuk2hbq+RcIEgCIJF0sqTNezatcstbWi8DDMAc8IJJ3DZZZcB8NZbbyXHwBQiPz8/5sFA48GadZIGDhzoLvPz4IMPAoGZYunM7bffbuW6F110Ucj7BQsWWLlPOmDqb5hyhcGsWLECIGmF+cWTFQRBsEhaebKmKtKgQYPcv4vX+ty2bZsk2wdhKm+VB+M1mJoHxntYsWJFVItaCrHx6quvJtuElOWDDz4AAk9XECjib5YHShYRPVmlVIZS6hOlVJZSaq1SamTR/vpKqQ+VUj8UvZZcl1soE9HWLqKvPUTb6InGk80HbtNaf62UOhxYqZT6ELgO+EhrPVEpNQoYBdxpz9TwnHzyye4iiT179gTCL/pn0mZycnJSqUqX59qa2LR5Le+v/EMPPcTNN98MBKp2maVQzASQFCKl267PSSltDzvsMCA0q8CMyyR7XCBiJ6u1zgayi/7+QymVBTQH+gA9ik6bAfwXD8Q085CHDx8OOOumm4Le4di8eTMQWK12+vTpVu0rD8nQtngea+3atd0iGY8//jgQWOOod+/ebrGYY489FoAjjjjCLU7y1VdfATBx4sREmJZwUq3txor5QWzbti3vv/9+kq1xSBVtTbgr3MzChQsX2rptuShXTFYpdQzQEVgONC4SGq11tlKqUSmfGQIMic/M9Ee0tYvoaw/Rtmyi7mSVUrWBOcDNWuvfo52TrrWeCkwtukZMpbCaNWvmzv829QmCCxgXZ9OmTe6gjClplkIhghIkU1ulFH379gXgggsuAAIFjcPNxf/xxx/d0nFDhw6N5Zaek0x9E4F56vBqwcbykExtu3XrRufOnc31gECdhzfeeCMps7vCEdW3ppSqiiPkLK21SS7drpRqWnS8KbDDjonpjWhrF9HXHqJtdET0ZJXz0zQNyNJaTw469DZwLTCx6HV+ooxq2LAhAO+88w4ArVu3pl690gcpzVK+Dz30EOAU7TZLqKQyydDWxPRM/Yajjz7aPWYGDGvVquXuO3jwIBCIb5klV/xAMvS1yXnnnedOG002qaBt48aNQ9oq4E6Gufrqq23dtvxorcvcgO6ABr4FVhVtFwINgI+AH4pe60dxLV3a1qtXL92rVy/95Zdf6r179+q9e/fqwsLCUrfc3Fydm5urX3jhBV27dm1du3btUq+dqC3Sv6+8m1fahtsyMjJ0RkaGfvbZZ3VBQYEuKChwtTXvZ8+erdu3b6/bt2/vO22TrW8its8++0x/9tln2vDuu++mjL6poO1ll11Wou3+9ttv+rfffvP0e4r074smu2AZUFqgpWekzwulI9raRfS1h2gbPSkz48u49yaQHcz27dvdx1xT0PjOO52sEFmGIzZMvYIbb7zRXe1XSC1MbY2uXbsm2ZLUZPny5W6o8LjjjkuyNaWTesOVgiAIaYTSHi4wmMw0mESgtU7ZtVREW7uIvvZId23FkxUEQbCIdLKCIAgWkU5WEATBItLJCoIgWMTrFK4cYH/Ra6rTkFA7j06WIVEi2tplH7Au2UZEid/0Teu262l2AYBS6iutdSdPbxoDfrEzGL/Y7Bc7g/GTzX6y1eAXm2OxU8IFgiAIFpFOVhAEwSLJ6GSnJuGeseAXO4Pxi81+sTMYP9nsJ1sNfrG53HZ6HpMVBEGoSEi4QBAEwSJxdbJKqUyl1Dql1IailSmFBCL62kO0tYdoW4w4ivZWBjYCrYBqwGqgXRnnZ+LkGW4ARtko0hzjvyMD+ATIAtYCI4v23w9sJaggscd2ib6irWibBtrGY0RXYFHQ+7uAuyII73l1+URuHn/J5dU36fqksbbSdkXbmLWNJ1zQHPgl6P2Won0hFC39uwZnpoQQPRH1VUoNUUp9haOvED3Sdu0h2hYjnk42XA1FXWKHs/TvPcCbcdyrIhJRX631VO3MPrnHG5PsoZQqfaVMC7cLs0/abmIQbYsRTye7BSduYWgBlLbQecoWDE5hKpq+Xi7DWtG09RLRthjxdLIrgOOVUi2VUtWA/jjLAYejuPBCZMqrr98pubibPaTt2kO0LUbMVbi01vlKqeHAIpwA9ota67WlnL4COD7We1VEYtDX73gWV5a2aw/RtiSezfhSSl0IvOvJzSyhZZ0kmzTTWmcn24hw2Gq7b775JpdffjkA27ZtA6B79+7uCqyJJFXbbkXoFzyb8aW1fs+rewn+I1U7WJC2a5OKoK3XRbsFn1OnTh2OOOIIAK666ioAmjRpAsBdd93FoUOHkmabXzj+eOcJ+aKLLjL5ojRq1AiAzp07W/FkKwodOnQAoHr16vzlL38BYNy4cQBEempfscKJup111lkA5OXlJcQm6WSFMmndujUAkyZNAuC0005zO9XiZGRkuI+/QulkZztO+5o1a+jUKeXrVKc0Rr+bb74ZgIsvvhgApRS1a9cGAp1rpE7WXOvdd53oxd///nf27NkTt41SIEYQBMEivvdke/XqxY033ghAly5dAEI8rYkTJwKwZcsW9/xnn30WgA8//NBLU33DKaecAsADDzzABRdcAECVKk5TUUrx+++/A3Dw4EEg8KibmZnpfnbVqlWe2uwn9u3bB8BPP/0knmycPPfcc0CgzSaC8847D4Bu3bq5Xm08iCcrCIJgEd96ssZ7feSRRzjssMMAx8sCWLduHXXq1AHgzjvvDPmcUoojjzwSEE/WUK+eM6N15syZAJx//vkAVKtWrcS5OTk5dO3aFcDVffXq1e77Fi1aAOLJlkX9+vUBOOmkk5Jsif9ZsGABUNKTPXDgAK+99hoQ6BeCY7Ldu3cHAmMONvFNJ2seV00HMHnyZACqVq3K+vXrAbj77rsBePvtt6lRowYAS5cuBQKjjgCfffaZN0b7hOuvvx6ACy+8sNRzdu3aBTghmU2bNgHQvn17+8alIWZAxoRZgunatSv/+9//ACTLIAoeeOABAKZPnx6yPy8vj61bt5b6ubp16wLw888/A4HvBAJZBh999FFCbJRwgSAIgkV848mOHDkScMIDwaxZs4ZzzjkHICTdwoQTgj1YgN9//53HH3/cpqm+Y8CAAWH379mzh++//x6Aa6+9FsD1YsFJ5xLKz+bNmwGYNWsWw4YNCzk2bNgw96nh/vvv99o035Gfnw+Etsto6N+/P4D7xBuM+X4SlfMtnqwgCIJFfOHJPv/88wwePBgIBK/nzp0LwD/+8Y+wCcNjxowJe61bbrnFnScuOPTp0weAUaOc5ZjeeecdwBm8Monz4ShtUoIQHTfddFMJT1awi9F7+PDhQGCsJ5ghQ4Yk9J7iyQqCIFgkpT3Zp59+GoDBgwdTUFAABFKDBg4cCDipGgaTUnTFFVe4o4cmfcMkLb/00kseWO4vTAzKxLGjpWfPnjbMqVCY9inYY8SIEYBTW6NhQ2e1m0qVSvqXJhshUTULDCnZyZo8wuuuuw5wQgSmcz399NNLnN+uXTsA3nvPKeiTkRGoA/zFF18AcMcdd1izN50xxTVMiotSyg3ZFM8x3LhxIwsXLvTWQJ8T7bx6ITym2I7pSHv37l3inOOOOw4Ir7HpUB944AFmz54NhDpuiUDCBYIgCBZJSU+2evXqQODxH5wQAEDTpk0BuO222wDo27cvzZs7i2GaGUrBv1hTp04FAvPFhdKpVasWEKgBMWnSpBIzaYI9WYPRtk+fPm5YRxBs06VLF95//30At/xmeVm71lm0YcKECQmzqzjiyQqCIFgkJT3Z3NxcIBAbqVmzJhs2bADCx1WMJ2U+V7t2bfezM2bMsG6vn6latao7mWPOnDlAIP6an5/vartmjbME16mnnkrVqlVDrmEGbwYNGuRObU704IEglEVZA4hlHTv11FMBZ0LOK6+8knC7IEU7WTPj5bLLLgNg3rx5bujAHDMDLE888YSb9/rxxx8DTqA7ESXK0hkTWrnqqquYNm1ayDFTCvL99993dTSjsqtXry6RH1uzZk3ACeH89NNPALz44otA4mbNpCvhOgBTXlJmfJXN8uXL3VKRZuBr3rx5AOzfvz/sZ2699VbAKcjtFRIuEARBsIhnq9WCvRVVzYwl8yumtXar89x3330Ju0+qrvgJ0WtrHvXNgKDJNwb49ttvgUD+665du1yvdfny5YCTHmcGt1544QUAOnbsCISm15kBhXHjxrF9+/YQG0xltGBSWVuw13YLCwuB8GGwzp07A7By5cq475PK+nq50rIp65mTkxOy/9prr405XJAyq9UKgiBURFIyJlteTEwwOLF7ypQpyTQpJalcuTLPP/88ANdccw0Af/75p5u+8swzzwCBuPd5553nxmtNMe6cnBxuuOEGIDBQZmbXXXjhhe687zPOOAOA119/3b2/WbbGeBOCU/sY4JJLLilxzBSc79evn6c2pTOm+paXiCcrCIJgkYierFIqA5gJNAEKgala6yeUUvWB14FjgJ+Aflrr3fZMLZ1XX30VcOpz+gmvtR09enSIBwtORoDxNjMzM4FApaLTTjvNrVJkngwee+yxErU7TRW02bNnu1MTTZUjUz0NAt6zV/ih7Zqle8J5sqlMMrQ14wnGG50zZ065psDecccd7liNp2ity9yApsCpRX8fDqwH2gGPAKOK9o8CHo7iWtrGduWVV+orr7xSFxYW6sLCQl1QUKCbNGmimzRpktD7RPr3lXfzWts//vhDFxQU6IKCAp2Xl6fz8vL05s2b9Y4dO/SOHTvcY8Hbk08+qZ988klduXJlXblyZSvfnw1t/dJ2zZaTk6NzcnLcNlxYWKgNbdu21W3btk0pfb3W9q9//atevXq1Xr16tds2W7ZsWeZnGjZsqBs2bKhHjhypR44cqQ8ePFiifefm5urc3Fz9t7/9zZq2EcMFWutsrfXXRX//AWQBzYE+gMn0nwFcGulaQiiirV1EX3uIttFTroEvpdQxQEdgOdBYa50NjuBKqZKrwjmfGQIktgpuMUwlHj/jhbZ79+51BwkrV64M4NZ9gEAZycWLFwPObDmzSKXfaxKkats1/Pjjj4A/BwW90HbKlCklJsFMmjQpbMF+g1l01VTl00FpcuvWrQNwl6Iyg7g2iLqTVUrVBuYAN2utf4+2DqbWeiowtegaOsLpFRLR1i6irz1E28hE1ckqpariCDlLa/1W0e7tSqmmRb9WTYEdtoyMxKJFiwAYO3ZsskyIGS+1PfHEExk0aBAQSLH69ddfmTRpEhBI0E6nugOp3nYNTzzxBAAzZ85MsiXRk2xtL720fJGIAwcOsGTJEgAuv/xyAA4ePJhwu4oTTXaBAqYBWVrryUGH3gauBSYWvc63YmEUmNlIv/32G+A8cp188skAKb2el9fa7t27l3//+9+JuJQv8EPbNXz55ZcA7Nixg0aNwj5hpxRea9u/f3/uueceILoVOXbt2uUWjDLaPvroo25f4SXReLLdgGuA75RSq4r2jcYR8Q2l1GBgM+BdxYX0QbS1i+hrD9E2StKidoHBFPJ+5JFH3AGbAQMGADL/O9VJZW1B9LVJtNrWqFEDCPw/Hz16tLtvxYoVQGCl5enTp7trdtkmkrYy40sQBMEiaeXJmjn0S5Ys4cQTTwQC8VpTozOeZWjSwRtIVVJZWxB9bZLu2oonKwiCYJG08mQNdevWdatHmTSPRNTmFG/AHqmsLYi+Nkl3bdOyk7WFNFR7pLK2IPraJN21lXCBIAiCRbwu2p0D7C96TXUaEmrn0ckyJEpEW7vsA9Yl24go8Zu+ad12PQ0XACilvtJad/L0pjHgFzuD8YvNfrEzGD/Z7CdbDX6xORY7JVwgCIJgEelkBUEQLJKMTnZqEu4ZC36xMxi/2OwXO4Pxk81+stXgF5vLbafnMVlBEISKhIQLBEEQLCKdrCAIgkXi6mSVUplKqXVKqQ1KqVGJOtdLlFIZSqlPlFJZSqm1SqmRRfvvV0ptVUqtKtouTIJtoq89u0Rbe3aJtsHEsSRwZWAj0AqoBqwG2sV7rtcbpS9tfD9wexLtEn1FW9E2DbSNx4iuwKKg93cBd5V1LpbXrre9efwll1ffpOuTxtpK2xVtY9Y2nnBBc+CXoPdbivaFoJylf18BTo3jXhWRiPoqpYYopb7C0dfXKKW8XAtb2q49RNtixNPJhqs8o0vscJb+HUUKLFbnMyLqq7Weqp0pfikTy4qDxzy8l7Rde4i2xYink90CZAS9bwH8GuW5QmTKq6/f6ezhvaTt2kO0LU4csZcqwI9ASwJB6xMjnJv0+Ek8m8dxw/Lqm3R94txeS2Ftpe2KtjFrG7Mnq7XOB4bjBK6zgDe01msjnCtESQz6+p1bvLqRtF17iLYlkZURyoGW6vLlJisry/27bdu2pZ6XytpCYvU97bTTAOjfvz/XX389AN9//z0AX375pXvemDFjAMjLy4v7nqmsb6q23WiJpK3M+BIEQbCI1ysjJJyqVaty0UUXAfDYY84A9bHHHptMkwTgtddeA+C4447jgw8+SLI1qYHxTO+9914AqlWr5h7r3r17yCsElrP/z3/+45WJggV8Hy5o3Lgx2dnZAOzfvx+ANm3asHXr1kTfSh65omD69OkAXH311QAUFBRwyy1OuHXKlCmlfi6VtYXE6NuwYUMAfvrpJwBq1apV5vmHDh0CYNCgQUDghysWUlnfVGm7sSLhAkEQhCTi+3BBMMYzOOaYY6x4skJkunbtCkClSs7v9/r168v0YCsSOTnO+nsTJ04EnLBB1apVAdi7dy8AderUcc+vUaMGAH369AHi82SFyJgw4+GHHw7A0KFDGThwYMg5X3zxBQDnn39+1NcVT1YQBMEmHifYJzwRuHHjxrqwsFAXFhZqQ7du3Xyd0J0q2vbp00d/9913+rvvvtMNGzbUDRs2LPP84cOH6wMHDugDBw7onTt36p07d+ozzzzT99ra0nfr1q1um83OztbZ2dk6HG3atNFt2rSRtmth69evn+7Xr5+eP3++PnjwoD548KDbn4TbduzYoXfs2FEubdMqXFD0hbnuvhAfzz//vDtYc8YZZwCwYMGCUs8fM2YMhx12GAA33XQTAJ9//rllK/3L2LFj3UyD5s1L1FBxMZoK8fP+++8DzuA4wFFHHVXiHJOXvGjRIpYtWwbA008/DcDBgwfLfU8JFwiCIFgkrTxZwxlnnOH+Ygmxk5ub6z4d1KxZs9TzunXrBkC9evXc88X7iszUqVN59913AVixYgUATZs2LXGeGTg0TxNC+WjUqBHgpBdecMEFQCA97pdfnKqM48eP53//+x8Af/zxBwA//vhjQu4vnqwgCIJFfO/J/vnnn+Tm5gJQvXp1IBBvEWJj6lRnaflmzZqxY8cOAJYsWVLivNq1awOBlKSqVauyadMmAJ577jkvTPU1I0aMoFOnTgA0adKk1PMWL17slUlpiYmnZmZmMmfOHAC3ZoTxWm0inqwgCIJFfO/J7tq1y61g1LFjxyRb429atmwJwFVXXQVAYWEhN9xwAwDbtm0rcf7rr78OwJlnngnAvn37pG5EGZxyyikAbi2HBg0auJM2yuKVV3y/upBnmAlJkyZNon///gDutO6FCxe6EzpiyRKIFd93skL8dOnSBYD33nsPCAxavfnmm8ybN6/E+Q8//DAAvXv3Dtn/yCOP2DTT95gSh/XqOcuZRdPBAjz44IMA/O1vf7NjWBrx5JNPAk69h88++wwIOANedqzBSLhAEATBImnpyTZu3DjZJqQ8Vao4X/3IkSN59NFHAVDKKSZk0rC6dOnC448/DsBdd90FwJFHHskVV1wRcq2PP/4YCHhcQnimTZsGwNFHHw04mprvoSzKmqgghGIGtLTWrt7J8mAN4skKgiBYxPf1ZAFWrlwJBAa+cnNzrSTD6zSqyTly5EgAJk+eHHwNAH777TcA6tev7x7bvHmzu8+kbh04cABIzDTmVNYW7LTdq6++2o3PGqpUqeKmxJmURFO8O57JCKmsbyK1NbV6jzrqKDc9a8iQIUAgNptoImmbFp3shAkTABg1ahQgnWxZ3HjjjQA89dRTgJNBYGa/XHfddUAgk+CFF16gdevWxe9D8Tazb98+wOkEgtf0Kg+prC14V1haKcWzzz4LwL/+9S/AyaAB6Ny5Mxs3bozpuqmsb6za9urVi08//RQI1BswtTbGjRvn6meOde3alW+++SZue4sTSVsJFwiCIFgkLQa+zCwjQ+XKld18zVh/+dMVUx3LFIl+6KGH3IGv4gwYMMB9xDI5tOH4+uuvAWL2YoUA1atXdz0wQ0FBQchrRSUjIwPATc1q0KABo0ePBuCJJ54AAoXRx44d6+po1lIra1adTcSTFQRBsEhaeAZNkdMAABKLSURBVLL5+fkl9pVVNaoiY1Y+ffHFF4GSTwHBtGjRokT60LBhw9xqRQZ5WkgcL7zwQol9L730EhAY1KmomJmdZkBwwoQJrgdbnPHjx7t/r127FggsHeM1ET1ZpVSGUuoTpVSWUmqtUmpk0f76SqkPlVI/FL3Wi3QtIRTR1i6irz1E23IQxdIQTYFTi/4+HFgPtAMeAUYV7R8FPJzsZSa2b9+ut2/frgsLC/X8+fP1/PnzE3p9C8tupKS29erV0/Xq1dNz5851l93IycnROTk51r47S8uaeK5vo0aNdKNGjfTKlSv1ypUr9U033RTV5zIyMnRGRoY+dOiQLk4qLj+TDG0nT56sJ0+erPPy8nReXl7Y5WHMskeFhYV69+7devfu3frss8/WZ599dtLabsRwgdY6G8gu+vsPpVQW0BzoA/QoOm0G8F/gzkjXs4lJ5/jrX//qFodIZVJV23vuuQdwdNy/fz+AW5LPTyRD3zfffBOAU089FXAGa0xh6PXr1wOBx94ePXrQvn17IJB+aB6FAWbPng3Azz//nAjTEkoytL311lsBp7wpOCmDph6EwYQJV69e7aYkrlmzJhG3j5lyxWSVUscAHYHlQOMiodFaZyulGpXymSHAkPjMTH9EW7uIvvYQbcsm6skISqnawKfAg1rrt5RSe7TWdYOO79Zalxl/sZ3Q/cYbbwBwySWXuCXPCgsLE3Z9bSmhO1W0NWlvZimUOnXquAW8TclDW9jSFrzVNzMzE4BnnnkGgFatWrnH9uzZAwQGsNq2bRviuQJordm5cycQ+D7MZI94SPe2m0wiaRtVCpdSqiowB5iltX6raPd2pVTTouNNgR3xGFpREW3tIvraQ7SNjoierHImtM8Admmtbw7a/yjwm9Z6olJqFFBfa/3/IlzLE0/28ssvd+crh0uJiZVEewOppq1J5Dbz6f/73//Ss2fPeC8bFTY8rWTqa+KpWVlZjBs3LurPHTx40Er6Ybq33WQSSdtoOtnuwFLgO8A8e4/Gib+8ARwFbAb+rrXeFeFaVsU0BSFq1KjB6aefDsCqVasSdn0LDTWltDVlDUeMGAHA0KFDE/ojVRaWOtmk61ujRo0Snawp9HLWWWe5+0z9iN69e4ddTy1e0r3tJpNI2kaTXbAMKO0i3rg5aYpoaxfR1x6ibfSkRRUuw7JlywBnnv3ZZ58NJHY2ks3BmXhJd28g2Yi+9kh3baV2gSAIgkXSypO1jXgD9khlbUH0tUm6ayuerCAIgkWkkxUEQbCIdLKCIAgWkU5WEATBIl4X7c4B9he9pjoNCbXz6GQZEiWirV32AeuSbUSU+E3ftG67nmYXACilvtJap3zdPL/YGYxfbPaLncH4yWY/2Wrwi82x2CnhAkEQBItIJysIgmCRZHSyU5Nwz1jwi53B+MVmv9gZjJ9s9pOtBr/YXG47PY/JCoIgVCQkXCAIgmCRuDpZpVSmUmqdUmpDUYFeIYGIvvYQbe0h2hYjjiWBKwMbgVZANWA10K6M8zNx8gw3ULRkcCpsQAbwCZAFrAVGFu2/H9gKrCraLvTYLtFXtBVt00DbeIzoCiwKen8XcFcihPdYzNLWj78fuD2Jdom+oq1omwbaxjPjqznwS9D7LUCX4icVLf17C85MieAK2mudZYJSg2K2rA3a/6j5W3tbLi6ivkHLKtfCaai+1TfVtAVpuzEi2hYjnphsuAuXSFXQWk8F7gHejONeFZGI+mqtp2pn9sk93phkD6VUmctGJ/p2YfZJ200Mom0x4ulkt+DELQwtgF9LOTd1fpr8Q8rq26FDBzp06MDu3bvZvXs3e/bsYc+ePfFe9rFE2BYlKattGiDaFiOeTnYFcLxSqqVSqhrQH3i7lHOLCy9Eprz6+p3OHt5L2q49RNtixByT1VrnK6WGA4twAtgvaq3XlnL6CuD4WO9VEYlBX0+YM2cOmZmZgLPcNcDXX3+diEuvScRFokHarj1E25LEVepQa/0e8F4U5xnh343nfhWNcurrgUVWucXLm0nbtYdoG4ospFgOPB4BLxe2tG3WrBkAS5cuBZzl1k2b2bZtGwAdO3YEYMeOHTHfJ5W1BWm7Nkl3bWVarSAIgkW8XhmhBIcffjgAN9xwAwCHDh2ia9euANStWxeAnj178v333wOQnZ1d6rV++cVJz3v11Vf55JNPrNlcUejQoQPTp08H4JhjjnH3P/aYkwiwfPlyID4PtiJiQjtLly6lUyen/nObNm0A+Omnn5JllmCJpHeyzzzzDAADBgwo87yTTjop5LUsBg8ezPbt2wF4/fXXAZgyZQoA69evj9nWikbz5s055ZRTSuzfvHkz4AyCCeWnZs2agNOWq1WrBsAVV1wBwMMPP5w0uwQ7SLhAEATBIkn3ZC+66KJSjx08eBAIeE7hWL9+Pa1btwagVq1aALRo0YImTZoAMHLkSCCQZiSebGQ6dOgAOGGX4lkLgwcP5qWXXkqGWWnD/v37Adi6dSsnnHACgNteBXtMnDjRfXIwg7XnnHOOe9yEvRL9XYgnKwiCYJGke7Ldu3cH4LTTTgNg5cqV7rF9+/YBgQGtSNSpUweAn3/+mSOOOCLkWP/+/QF4+eWX4zO4AnDTTTcBcMQRR7Bq1SoA+vbtCzjaColh8uTJPPfccwBhY99C7Fx66aWcfPLJAPTu3RuALl1K1KkhOIW1YcOGAO54TuPGjRNiS9I72aysrJDXeBg4cCBASAdbUFAABEbEhdLZuNEphpSR4cx03LNnj6updK6JZ/Hixe7fxtnIyMiI2qmo6GRkZLgaFn/Er169OlWrVgUC2RybN29223Y4zHnVq1dPqJ0SLhAEQbBI0j3ZeKlWrZqbSmQeC4I577zzgMCMJaEkgwYNApzZXBB4hHr77bfdkI1gB+M9Va5cGXCexh588MFkmpTy9OvXD4DnnnuuRFgwHGaQKzs7m6ZNmwJw3HHHATBt2jQgkK8PiX9qE09WEATBIr71ZC+//HIAhg4dSs+ePUOOFRYWct999wHw1VdfeW6bn6hfvz7nn39+2GM5OTllzkB64IEHAGjVqpW77+qrr06ofelO8dohJsVIKJ17770XIKwXa8ZgJkyYwJIlSwBYvXq1e9ykaY0bNw4I9WBNTeQLLrggofaKJysIgmAR33myxusy02XDlfjTWrtxlfz8fO+M8yEFBQVu+lxxLYNHvw0PPfSQ632ZehMmdQ7gqquuAgK1DiQrQUgUJg3TxFOD+f3334HA9Px33y27emKLFi1K7Fu0aBEQSOFKFL7rZM0gTVn1UytXrszMmTMBGD9+PADvvPMOAK+88opb2ESAPn36cPzxTt1k03nu3bsXcGYkGbp16wY4A4mmqIkhLy/P/dyRRx4J4Bbo6dWrl5saJgjxMGbMGAA3NQsCaYfmWFmda4MGDVwnoF27diHHNm7cyNy5cxNqr0HCBYIgCBbxnSf7yiuvAIFfotatW3PYYYeVev5RRx0FwLBhwwC48cYbee211wC4/fbbgbLLJ6Yr5hH/2GOPdfeZdK033ngDgDVr1rh1DCZMmADA6aefzoEDB4DA7Ly7774bcDyFt956CwjUkRDKxjyReVk83688+eSTANxzj7M48/79+93wYfBTV2mMGTPGrWViMIXnzz333KiuEQviyQqCIFjEd57swoULQ15btWrlBrHNlLkBAwaEnZgAjudw5ZVXAoF6Ce3ataOwsNCq3anGxRdfDAS8UMCNYw8fPhxwlp4xRbvN3Prc3Fw+/PBDAFdHU+N36tSp5ObmAvD5558DSDw2AuLBRs/zzz8f8hot1157LRCoyQG4/99N7QhbXizgfMlebYD2ahsxYoQeMWKE3rRpk960aZMuLCwsdXv00UejuqaXWtnWdtKkSXrSpEm6oKDA3Yqfs3HjxpDjBQUF+tJLL3WPZ2Zm6szMzJDjs2bN0rNmzSr395Vs/ZLRdlu2bFmiLQbrm8gt2fols18w2ga309GjR+vRo0d7oq2ECwRBECziu3BBtJgg+bPPPgvA2rXO0u8mXSmYE0880TvDUoQGDRoATvhkxYoVIcdMutaRRx7pDsyYga958+aFFPU21zDnBIcfhPJjSksK8WPqEoRL94yUR5tIxJMVBEGwSNp6sgYz48ukG4XzZL/77jtPbUolguJiZR4zBY/37t1LlSpOs9m5cycQGBTbtWuXbXMFISqqVavmTpoxbVhr7dYs8PL/fERPVimVoZT6RCmVpZRaq5QaWbS/vlLqQ6XUD0Wv9eybm16ItnYRfe0h2kZPNJ5sPnCb1vprpdThwEql1IfAdcBHWuuJSqlRwCjgThtGZmRkcOedzqVNbNUs8R0JU6cz3PIeJo3js88+S4SZsZA0bU3th4EDB3L66acDkJmZCeB6AMEVoUxdXqWUOxnBxF9TuD5B0ttueSlrYk2KkZLamkkwI0eOpH379iHHli5dylNPPQXgbcpmDOkW84FewDqgadG+psC6RKdqNG/eXDdv3lxv3brVTcOoV6+erlevXsTPNmvWTDdr1kzPmDFDz5gxI2zq1tatW/XWrVtTJg3GS2179Oihe/TooQ8dOuSmtYRLdSm+HTx4UM+dO1fPnTvXdylGXuobzRYuhWvs2LEJv0+6td1wW506dXSdOnX0smXL9LJly0La7Lhx4/S4ceN0pUqVkqJtuWKySqljgI7AcqCx1job5y7ZSqlGpXxmCDCkPPepiIi2dhF97SHaRqAcv1S1gZXAZUXv9xQ7vjvRv1jmVyn4l75bt266W7duumbNmrpmzZoh55t9zzzzjD506JA+dOhQCU9Ba+0eu/TSS8uV/G3RC/BcW7Ndc801OisrS2dlZYX1ZD/44AP9wQcf6PHjx+vx48f7Mlk+mfqWtVWrVk1nZ2fr7Oxs33qyqaJtx44ddceOHUPa7s6dO/XOnTut6FkebaNK4VJKVQXmALO01m8V7d6ulGpadLwpsCOaawmhiLZ2EX3tIdpGhyr6JSn9BCeTdwawS2t9c9D+R4HfdCDAXV9r/f8iXKvsmxVj1KhRQCARPpgtW7YATiUegwl6hyvIa8jLy+Oaa64B4M033yyPOWitSy9iGwPJ1DbVSLS24A99zaChqbvxzTffuDU1Ekm6tl0zoP3QQw8BgaVjcnJyOPPMMwH79TMiahuFK98dxy3+FlhVtF0INAA+An4oeq2f6MeC1q1b69atW+slS5aUWXugrC0/P1/n5+frmTNn6pkzZ+pevXqlzCNXMrVNtc3So2zK67tw4UK9cOFCt71mZWX5Qt9U0fbTTz/Vn376aYkB2nvvvTdl2m7EgS+t9TKgtJ66Zyn7hSgQbe0i+tpDtI2elJ7xtX79esB5BBg8eDAAF110ERCYsdG3b1/3/A0bNrh/m7nJ3377LeDkyAlCqjFixAggsL7UrFmzkmmOr+jUqVPIarMACxYsAGD+/PnJMCksUrtAEATBIhEHvhJ6MxmcsYZoaxfR1x6xajtjxgx3dVqz+Oe5554LwOrVqxNkXWQiaSuerCAIgkVSOiYrCIJQGgsWLHA92dtuuw3w1oONFgkXlIN0fORKFVJZWxB9bZLu2kq4QBAEwSJehwtygP1Fr6lOQ0LtPDpZhkSJaGuXfTgVpvyA3/RN67brabgAQCn1lda6k6c3jQG/2BmMX2z2i53B+MlmP9lq8IvNsdgp4QJBEASLSCcrCIJgkWR0slOTcM9Y8IudwfjFZr/YGYyfbPaTrQa/2FxuOz2PyQqCIFQkJFwgCIJgEelkBUEQLOJZJ6uUylRKrVNKbSiqmJ4SlLF+/P1Kqa1KqVVF24XJtrUsRF97iLb2qBDa2qhIH6byeWVgI9AKqAasBtp5ce8obGsKnFr09+HAeqAdcD9we7LtE32Tbr9oK9rGpa1XnmxnYIPW+ketdR7wGtDHo3uXidY6W2v9ddHffwBZQPPkWlVuRF97iLb2qBDaetXJNgd+CXq/hRRsDMXWjwcYrpT6Vin1olKqXtIMi4zoaw/R1h4VQluvOtlwVWpSKndMKVUbZ3njm7XWvwNTgGOBU4Bs4LEkmhcJ0dceoq09KoS2XnWyW4CMoPctgF89undEwq0fr7XerrUu0FoXAs/jPNqkKqKvPURbe1QIbb3qZFcAxyulWiqlqgH9gbc9uneZFK0fPw3I0lpPDtrfNOi0vsAar20rB6KvPURbe1QIbT0pdai1zldKDQcW4Ywovqi1XuvFvaOgG3AN8J1SalXRvtHAlUqpU3AeX34ChibHvMiIvvYQbe1RUbSVabWCIAgWkRlfgiAIFpFOVhAEwSLSyQqCIFhEOllBEASLSCcrCIJgEelkBUEQLCKdrCAIgkX+PxBc7B+UDsCZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load the digits dataset\n",
    "def load_digits(show_sample = True):\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    \n",
    "    #show first 100 images\n",
    "    if show_sample == True:\n",
    "        nImg = 4\n",
    "        for i in range(nImg*nImg):\n",
    "            plt.subplot(nImg, nImg, i+1)\n",
    "            plt.imshow(x_train[i], cmap = 'Greys_r')\n",
    "        plt.show()\n",
    "        \n",
    "    x_train_1 = np.reshape(x_train, [x_train.shape[0], x_train.shape[1] * x_train.shape[2]])\n",
    "    x_test_1 = np.reshape(x_test, [x_test.shape[0], x_test.shape[1] * x_test.shape[2]])\n",
    "    \n",
    "    return x_train_1, y_train, x_test_1, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 1: Activation functions: implement the softmax function. 5 points\n",
    "def sigm(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def dsigm(z):\n",
    "    return sigm(z)*(1 - sigm(z))\n",
    "\n",
    "def softmax(z):\n",
    "    ''' softmax function for the output layer\n",
    "\n",
    "        parameters:\n",
    "            z: net input vector of the output layer\n",
    "        \n",
    "        return the result vector     \n",
    "    '''\n",
    "    ## add your code here\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=0)\n",
    "    ##    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-20-143fde8e8c7f>, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-143fde8e8c7f>\"\u001b[0;36m, line \u001b[0;32m43\u001b[0m\n\u001b[0;31m    if self.activation is 'softmax':\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "## Task 2: create the layer class. 10 points\n",
    "\n",
    "class Layer:\n",
    "    \"\"\" Regular densely-connected NN layer   \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, units, input_dim, activation = None): # 5 points\n",
    "        '''initialize weights and bias. \n",
    "            \n",
    "            parameters:\n",
    "                units: the number of hidden nodes\n",
    "                input_dim: dimensionality of the layer input\n",
    "                activation: activation function\n",
    "        '''\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        ## add your code here\n",
    "        ## check here: https://www.deeplearning.ai/ai-notes/initialization/\n",
    "        np.random.seed(0)\n",
    "        self.W = np.random.randn(input_dim)\n",
    "        #self.bias =  # bias\n",
    "        \n",
    "        #self.gW =   # gradient of wights\n",
    "        #self.gb =  # gradient of bias\n",
    "        ##\n",
    "        \n",
    "    def run(self, inputs): # 5 points\n",
    "        ''' calculate the net input and activation output of the current layer\n",
    "        \n",
    "            parameters:\n",
    "                inputs: layer input. input=(n_sample * n_features)\n",
    "          \n",
    "            return:\n",
    "                self.output: the activation output\n",
    "        '''\n",
    "        \n",
    "        ## add your code here\n",
    "        # self.net =     \n",
    "        if self.activation is 'sigm':\n",
    "            #self.output = \n",
    "        if self.activation is 'softmax':\n",
    "            #self.output = \n",
    "        ##\n",
    "        \n",
    "        return self.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Task 3: complete the following NN class. 60 points\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.layers=[]\n",
    "        \n",
    "    # Task 3.1: implement the 'add' function. 5 points     \n",
    "    def add(self, units, input_dim, activation = 'sigm'):\n",
    "        '''add one layer to neural network\n",
    "        \n",
    "            parameters:\n",
    "                units: the number of nodes of current layer\n",
    "                input_dim: input dimension (the number of nodes of the previous layer)\n",
    "                activation: the activation function\n",
    "        '''\n",
    "        \n",
    "        ## add your code here\n",
    "        \n",
    "        #layer = \n",
    "        #\n",
    "        \n",
    "        ##\n",
    "        \n",
    "    # Task 3.2: implement the cross-entropy loss. 5 points   \n",
    "    def loss(self, y_pred, y):\n",
    "        '''loss function: 1/n_samples*sum_samples(sum_output(-y_i*log(y_pred_i)))\n",
    "            \n",
    "            parameters:\n",
    "                y_pred: predictions(n_samples * 10)\n",
    "                y: target(one-hot vectors: n_samples * 10)\n",
    "            return:\n",
    "                loss\n",
    "        '''\n",
    "        \n",
    "        m = y.shape[0] # the number of samples\n",
    "        \n",
    "        ## add your code here\n",
    "        \n",
    "        #y_pred =  \n",
    "        #loss = \n",
    "        ##\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    # Task 3.3: implement the forward propagation process. 5 points.\n",
    "    def forward_prop(self, inputs):\n",
    "        '''forward propagation calculates net input and output for all layers\n",
    "            \n",
    "            parameters:\n",
    "                inputs: input data(n_samples * n_features)\n",
    "            \n",
    "            return:\n",
    "                out: the output of the last layer\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        nLayers = len(self.layers)\n",
    "        \n",
    "        ## add your code here\n",
    "        for i in range(nLayers):\n",
    "            #\n",
    "            #\n",
    "        ##\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    # Task 3.4: implement the prediction function. 5 points\n",
    "    def predict_class(self, x):\n",
    "        '''predict class lables (0, 1, 2, 3, ..., 9) for data samples\n",
    "        \n",
    "            parameters:\n",
    "                x: input(n_samples * n_features) \n",
    "            return:\n",
    "                class labels\n",
    "        '''\n",
    "        ##add your code here\n",
    "        #\n",
    "        #  \n",
    "        ##\n",
    "        \n",
    "    # Task 3.5: complete the following 'train' function. 10 points.\n",
    "    def train(self, inputs, targets, lr = 0.001, batch_size = 32, epochs = 50):\n",
    "        '''implement the SGD process and use Back-Propagation algorithm to calculate gradients \n",
    "            \n",
    "            parameters:\n",
    "                inputs: training samples\n",
    "                targets: training targets\n",
    "                lr: learning rate\n",
    "                batch_size: batch size\n",
    "                epochs: max number of epochs\n",
    "                \n",
    "            return:\n",
    "                loss_hist\n",
    "        '''\n",
    "        \n",
    "        m = len(targets)  \n",
    "        #print(m, targets.shape)\n",
    "        loss_hist = np.zeros(epochs)\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            #shuffle the data\n",
    "            idx = np.arange(m)\n",
    "            np.random.shuffle(idx)\n",
    "            inputs = inputs[idx]\n",
    "            targets = targets[idx]\n",
    "            \n",
    "            for b in range(int(m/batch_size)):\n",
    "                b_start= b*batch_size\n",
    "                b_end = min((b+1)*batch_size, m)\n",
    "                \n",
    "                x_batch = inputs[b_start:b_end, :]\n",
    "                y_batch = targets[b_start:b_end, :]\n",
    "                \n",
    "                ## add your code here\n",
    "                \n",
    "                # 1. run forward propagation\n",
    "                \n",
    "                # 2. call BP to calculate all gradients\n",
    "               \n",
    "                # 3. update all weights and bias\n",
    "                \n",
    "                ##\n",
    "                \n",
    "            lr = lr*0.95\n",
    "            \n",
    "            ## add your code here\n",
    "            \n",
    "            # 4. calculate and record the loss of current epoch\n",
    "            #\n",
    "            #loss_hist[i] = \n",
    "            \n",
    "            # 5. print out the loss of current epoch\n",
    "            ##\n",
    "            \n",
    "        return loss_hist\n",
    "   \n",
    "    # Task 3.6: implement the BP algorithm. 30 points\n",
    "    def BP(self, x, y):\n",
    "        ''' Back-propagation algorithm\n",
    "            \n",
    "            parameters:\n",
    "            x: input samples (n_samples * n_features)\n",
    "            y: ont-hot targets (n_samples * 10)\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        nLayers = len(self.layers)\n",
    "        m_batch = x.shape[0]\n",
    "        \n",
    "        ## add your code here\n",
    "        # 1. calculate gradients for the hidden-to-output layer. 15 points\n",
    "\n",
    "        # 2. calculate gradients for the input-to-hidden layers. 15 points\n",
    "        \n",
    "        ##\n",
    "            \n",
    "    # Task 3.7: update all weights and bias. 5 points            \n",
    "    def updateWeights(self, lr):\n",
    "        nLayers = len(self.layers)\n",
    "        \n",
    "        ##add your code here\n",
    "        for i in range(nLayers):\n",
    "            #self.layers[i].W \n",
    "            #self.layers[i].bias \n",
    "        ##\n",
    "            \n",
    "    # Task 3.8: calculate the accuracy. 5 points           \n",
    "    def Acc(self, y, y_pred):\n",
    "        '''accuracy\n",
    "        \n",
    "            parameters:\n",
    "                y: target: categorical values (0, 1, ...9). n_samples * 1\n",
    "                y_pred: prediction: 0,1,2, ..9. n_samples *1\n",
    "        '''\n",
    "        \n",
    "        ##add your code here\n",
    "        \n",
    "        ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Evaluation. 15 points\n",
    "   \n",
    "# 1. create a one-hidden layer NN.\n",
    "## add your code here\n",
    "\n",
    "#    The hidden layer activation is sigmoid and the outputlayer activation is the softmax. \n",
    "#    5 points\n",
    "#nn = \n",
    "#nn.add()\n",
    "#nn.add()\n",
    "##\n",
    "\n",
    "# 2. train the NN. \n",
    "x_train, y_train, x_test, y_test = load_digits(show_sample = True)\n",
    "y_train_onehot = keras.utils.to_categorical(y_train)\n",
    "# \n",
    "\n",
    "# 3. calculte and print out the test and training accuracy. 10 points\n",
    "\n",
    "## add your code here\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
